{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyYfCKaz2-Wj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58592ba8-2a02-4f83-f178-d3fa42574392"
      },
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#importing the natural language toolkit and downloading the important libraries\n",
        "import nltk\n",
        "nltk.download('popular')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYadC_ZiDuIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670e8118-e584-46b8-eb81-cef2a958eafa"
      },
      "source": [
        "pip install docx2txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3959 sha256=6bd7477376b5d403a26ad646e70086fb1326531c137b07766fbc271343885a6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqsf1pcZ3RIh"
      },
      "source": [
        "#importing docx2text and changing the docx file imported to text\n",
        "import docx2txt\n",
        "k = docx2txt.process(\"text.docx\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJQyDjQE3Wl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f23179-ff0d-44ab-a2c6-d6e3f96320e6"
      },
      "source": [
        "#finding the number of characters in the text saved as in the name k\n",
        "len(k)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1221"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENRTE4ld3Zhp"
      },
      "source": [
        "#tokenization basically refers to splitting up a larger body of text into smaller lines, words or even creating words for a non-English language.\n",
        "#importing sent_tokenize function from nltk and sentence tokenizing the text\n",
        "from nltk.tokenize import sent_tokenize\n",
        "corpus=sent_tokenize(k)\n",
        "cor=corpus.copy()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T7ObeTD3f7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed326fd-310f-4600-f954-666e1daa2cc9"
      },
      "source": [
        "#finding the number of sentences\n",
        "len(cor)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMkQv1I33j9x"
      },
      "source": [
        "#importing the re library and cleaning the text of any punctuation marks, numbers and eddy spaces\n",
        "import re\n",
        "corpuss=[]\n",
        "for k in corpus:\n",
        "  text = re.sub('[^a-zA-Z]', ' ', k)#allows just a-z and A-Z and replaces all other characters with space\n",
        "  text = re.sub(r'\\s+', ' ', text)#replaces multiple space sequences with a single space\n",
        "  corpuss.append(text)\n",
        "corpus=corpuss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja3F6QWh3oeJ"
      },
      "source": [
        "#changing all the alphabetic characters to lower space\n",
        "import string\n",
        "corpuss=[s.lower() for s in corpus]\n",
        "corpus=corpuss.copy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ycUG1T03rsp"
      },
      "source": [
        "#importing all the stopwords in the english language from the nltk package\n",
        "from nltk.corpus import stopwords\n",
        "stop_words=stopwords.words('english')\n",
        "def remove_stopwords(sen):                 ## Here we are removing all the stopwords form the sentence\n",
        "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
        "    return sen_new\n",
        "cleaned = [remove_stopwords(r.split()) for r in corpuss]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AT1wdao3v3I"
      },
      "source": [
        "#here we are defining a method to word tokenize\n",
        "def Tokenization(corpus):\n",
        "    y=[]\n",
        "    for i in range(0,len(corpus)):\n",
        "      a=corpus[i].split(\" \")\n",
        "      y.append(a)\n",
        "    return y"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNMUCv7U3zqp"
      },
      "source": [
        "#defining a function to renove stop words and calling the Tokenization method to tokenize\n",
        "def remove_stop_words(corpus):\n",
        "\n",
        "    stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "    corpus_wo_stopwords=[]\n",
        "    a=Tokenization(corpus)\n",
        "    for i in a:\n",
        "      x=[]\n",
        "      for j in i:\n",
        "        if j not in stop_words:\n",
        "          x=x+[j]\n",
        "      corpus_wo_stopwords+=[x]\n",
        "\n",
        "    return corpus_wo_stopwords\n",
        "#word tokenizing the raw text and removing stopwords from a copy of the raw text that we have kept untouched without doing sentence tokenization because these words will be used to find their word vectors\n",
        "PP_corpus = remove_stop_words(corpus)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESoDve0u35II"
      },
      "source": [
        "\n",
        "#getting the unique words from the word tokenized list\n",
        "def get_unique_words(PP_corpus):\n",
        "    unique_words=set()\n",
        "    for i in PP_corpus:\n",
        "      for j in i:\n",
        "          unique_words.add(j)\n",
        "    return unique_words\n",
        "\n",
        "unique_words = get_unique_words(PP_corpus)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdE5gx9k38Z5"
      },
      "source": [
        "#mapping each unique words in a dictionry against an integer\n",
        "def mapping(unique_words):\n",
        "    y1=unique_words\n",
        "    ind=list(range(len(y1)))\n",
        "    d = {k:v for k,v in zip(y1,ind)}\n",
        "    return d\n",
        "\n",
        "word2int = mapping(unique_words)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c80vBM684ALJ"
      },
      "source": [
        "\n",
        "\n",
        "#getting the data using skip gram model.Skip gram model here is giving us the output as a list of tuples where each tuple has two elements. The first element is the centre word and the second element is the context word. It depends on thewindow length we have provided.\n",
        "import pandas as pd\n",
        "\n",
        "def data_gen(PP_corpus, window_size):\n",
        "\n",
        "    w=window_size\n",
        "    y=PP_corpus\n",
        "    li=[]\n",
        "    k=0\n",
        "    for i in range(len(y)):\n",
        "      for j in range(len(y[i])):\n",
        "        for h in range(-w,w+1):\n",
        "          if(j+h>=0 and j+h<len(y[i])):\n",
        "            if(not(j==j+h)):\n",
        "              li+=[(y[i][j],y[i][j+h])]\n",
        "    data = li\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "data = data_gen(PP_corpus, 2)\n",
        "df = pd.DataFrame(data, columns = ['input', 'label'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtqHZLgJ4Dax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6d4d69-065e-4c62-d9bc-5a30356ef87b"
      },
      "source": [
        "\n",
        "data"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('student', 'life'),\n",
              " ('student', 'dynamic'),\n",
              " ('life', 'student'),\n",
              " ('life', 'dynamic'),\n",
              " ('life', 'transformative'),\n",
              " ('dynamic', 'student'),\n",
              " ('dynamic', 'life'),\n",
              " ('dynamic', 'transformative'),\n",
              " ('dynamic', 'period'),\n",
              " ('transformative', 'life'),\n",
              " ('transformative', 'dynamic'),\n",
              " ('transformative', 'period'),\n",
              " ('transformative', 'filled'),\n",
              " ('period', 'dynamic'),\n",
              " ('period', 'transformative'),\n",
              " ('period', 'filled'),\n",
              " ('period', 'multitude'),\n",
              " ('filled', 'transformative'),\n",
              " ('filled', 'period'),\n",
              " ('filled', 'multitude'),\n",
              " ('filled', 'experiences'),\n",
              " ('multitude', 'period'),\n",
              " ('multitude', 'filled'),\n",
              " ('multitude', 'experiences'),\n",
              " ('multitude', 'challenges'),\n",
              " ('experiences', 'filled'),\n",
              " ('experiences', 'multitude'),\n",
              " ('experiences', 'challenges'),\n",
              " ('experiences', ''),\n",
              " ('challenges', 'multitude'),\n",
              " ('challenges', 'experiences'),\n",
              " ('challenges', ''),\n",
              " ('', 'experiences'),\n",
              " ('', 'challenges'),\n",
              " ('time', 'young'),\n",
              " ('time', 'individuals'),\n",
              " ('young', 'time'),\n",
              " ('young', 'individuals'),\n",
              " ('young', 'embark'),\n",
              " ('individuals', 'time'),\n",
              " ('individuals', 'young'),\n",
              " ('individuals', 'embark'),\n",
              " ('individuals', 'journey'),\n",
              " ('embark', 'young'),\n",
              " ('embark', 'individuals'),\n",
              " ('embark', 'journey'),\n",
              " ('embark', 'self'),\n",
              " ('journey', 'individuals'),\n",
              " ('journey', 'embark'),\n",
              " ('journey', 'self'),\n",
              " ('journey', 'discovery'),\n",
              " ('self', 'embark'),\n",
              " ('self', 'journey'),\n",
              " ('self', 'discovery'),\n",
              " ('self', 'personal'),\n",
              " ('discovery', 'journey'),\n",
              " ('discovery', 'self'),\n",
              " ('discovery', 'personal'),\n",
              " ('discovery', 'growth'),\n",
              " ('personal', 'self'),\n",
              " ('personal', 'discovery'),\n",
              " ('personal', 'growth'),\n",
              " ('personal', 'academic'),\n",
              " ('growth', 'discovery'),\n",
              " ('growth', 'personal'),\n",
              " ('growth', 'academic'),\n",
              " ('growth', 'exploration'),\n",
              " ('academic', 'personal'),\n",
              " ('academic', 'growth'),\n",
              " ('academic', 'exploration'),\n",
              " ('academic', ''),\n",
              " ('exploration', 'growth'),\n",
              " ('exploration', 'academic'),\n",
              " ('exploration', ''),\n",
              " ('', 'academic'),\n",
              " ('', 'exploration'),\n",
              " ('typical', 'day'),\n",
              " ('typical', 'student'),\n",
              " ('day', 'typical'),\n",
              " ('day', 'student'),\n",
              " ('day', 'marked'),\n",
              " ('student', 'typical'),\n",
              " ('student', 'day'),\n",
              " ('student', 'marked'),\n",
              " ('student', 'attending'),\n",
              " ('marked', 'day'),\n",
              " ('marked', 'student'),\n",
              " ('marked', 'attending'),\n",
              " ('marked', 'classes'),\n",
              " ('attending', 'student'),\n",
              " ('attending', 'marked'),\n",
              " ('attending', 'classes'),\n",
              " ('attending', 'engaging'),\n",
              " ('classes', 'marked'),\n",
              " ('classes', 'attending'),\n",
              " ('classes', 'engaging'),\n",
              " ('classes', 'thought'),\n",
              " ('engaging', 'attending'),\n",
              " ('engaging', 'classes'),\n",
              " ('engaging', 'thought'),\n",
              " ('engaging', 'provoking'),\n",
              " ('thought', 'classes'),\n",
              " ('thought', 'engaging'),\n",
              " ('thought', 'provoking'),\n",
              " ('thought', 'discussions'),\n",
              " ('provoking', 'engaging'),\n",
              " ('provoking', 'thought'),\n",
              " ('provoking', 'discussions'),\n",
              " ('provoking', 'absorbing'),\n",
              " ('discussions', 'thought'),\n",
              " ('discussions', 'provoking'),\n",
              " ('discussions', 'absorbing'),\n",
              " ('discussions', 'knowledge'),\n",
              " ('absorbing', 'provoking'),\n",
              " ('absorbing', 'discussions'),\n",
              " ('absorbing', 'knowledge'),\n",
              " ('absorbing', 'passionate'),\n",
              " ('knowledge', 'discussions'),\n",
              " ('knowledge', 'absorbing'),\n",
              " ('knowledge', 'passionate'),\n",
              " ('knowledge', 'professors'),\n",
              " ('passionate', 'absorbing'),\n",
              " ('passionate', 'knowledge'),\n",
              " ('passionate', 'professors'),\n",
              " ('passionate', ''),\n",
              " ('professors', 'knowledge'),\n",
              " ('professors', 'passionate'),\n",
              " ('professors', ''),\n",
              " ('', 'passionate'),\n",
              " ('', 'professors'),\n",
              " ('lectures', 'students'),\n",
              " ('lectures', 'huddle'),\n",
              " ('students', 'lectures'),\n",
              " ('students', 'huddle'),\n",
              " ('students', 'libraries'),\n",
              " ('huddle', 'lectures'),\n",
              " ('huddle', 'students'),\n",
              " ('huddle', 'libraries'),\n",
              " ('huddle', 'poring'),\n",
              " ('libraries', 'students'),\n",
              " ('libraries', 'huddle'),\n",
              " ('libraries', 'poring'),\n",
              " ('libraries', 'textbooks'),\n",
              " ('poring', 'huddle'),\n",
              " ('poring', 'libraries'),\n",
              " ('poring', 'textbooks'),\n",
              " ('poring', 'notes'),\n",
              " ('textbooks', 'libraries'),\n",
              " ('textbooks', 'poring'),\n",
              " ('textbooks', 'notes'),\n",
              " ('textbooks', 'collaborating'),\n",
              " ('notes', 'poring'),\n",
              " ('notes', 'textbooks'),\n",
              " ('notes', 'collaborating'),\n",
              " ('notes', 'peers'),\n",
              " ('collaborating', 'textbooks'),\n",
              " ('collaborating', 'notes'),\n",
              " ('collaborating', 'peers'),\n",
              " ('collaborating', 'group'),\n",
              " ('peers', 'notes'),\n",
              " ('peers', 'collaborating'),\n",
              " ('peers', 'group'),\n",
              " ('peers', 'projects'),\n",
              " ('group', 'collaborating'),\n",
              " ('group', 'peers'),\n",
              " ('group', 'projects'),\n",
              " ('group', ''),\n",
              " ('projects', 'peers'),\n",
              " ('projects', 'group'),\n",
              " ('projects', ''),\n",
              " ('', 'group'),\n",
              " ('', 'projects'),\n",
              " ('yet', 'student'),\n",
              " ('yet', 'life'),\n",
              " ('student', 'yet'),\n",
              " ('student', 'life'),\n",
              " ('student', 'academics'),\n",
              " ('life', 'yet'),\n",
              " ('life', 'student'),\n",
              " ('life', 'academics'),\n",
              " ('life', ''),\n",
              " ('academics', 'student'),\n",
              " ('academics', 'life'),\n",
              " ('academics', ''),\n",
              " ('', 'life'),\n",
              " ('', 'academics'),\n",
              " ('vibrant', 'tapestry'),\n",
              " ('vibrant', 'social'),\n",
              " ('tapestry', 'vibrant'),\n",
              " ('tapestry', 'social'),\n",
              " ('tapestry', 'interactions'),\n",
              " ('social', 'vibrant'),\n",
              " ('social', 'tapestry'),\n",
              " ('social', 'interactions'),\n",
              " ('social', 'extracurricular'),\n",
              " ('interactions', 'tapestry'),\n",
              " ('interactions', 'social'),\n",
              " ('interactions', 'extracurricular'),\n",
              " ('interactions', 'activities'),\n",
              " ('extracurricular', 'social'),\n",
              " ('extracurricular', 'interactions'),\n",
              " ('extracurricular', 'activities'),\n",
              " ('extracurricular', 'newfound'),\n",
              " ('activities', 'interactions'),\n",
              " ('activities', 'extracurricular'),\n",
              " ('activities', 'newfound'),\n",
              " ('activities', 'friendships'),\n",
              " ('newfound', 'extracurricular'),\n",
              " ('newfound', 'activities'),\n",
              " ('newfound', 'friendships'),\n",
              " ('newfound', ''),\n",
              " ('friendships', 'activities'),\n",
              " ('friendships', 'newfound'),\n",
              " ('friendships', ''),\n",
              " ('', 'newfound'),\n",
              " ('', 'friendships'),\n",
              " ('students', 'join'),\n",
              " ('students', 'clubs'),\n",
              " ('join', 'students'),\n",
              " ('join', 'clubs'),\n",
              " ('join', 'participate'),\n",
              " ('clubs', 'students'),\n",
              " ('clubs', 'join'),\n",
              " ('clubs', 'participate'),\n",
              " ('clubs', 'sports'),\n",
              " ('participate', 'join'),\n",
              " ('participate', 'clubs'),\n",
              " ('participate', 'sports'),\n",
              " ('participate', 'attend'),\n",
              " ('sports', 'clubs'),\n",
              " ('sports', 'participate'),\n",
              " ('sports', 'attend'),\n",
              " ('sports', 'events'),\n",
              " ('attend', 'participate'),\n",
              " ('attend', 'sports'),\n",
              " ('attend', 'events'),\n",
              " ('attend', 'immersing'),\n",
              " ('events', 'sports'),\n",
              " ('events', 'attend'),\n",
              " ('events', 'immersing'),\n",
              " ('events', 'diverse'),\n",
              " ('immersing', 'attend'),\n",
              " ('immersing', 'events'),\n",
              " ('immersing', 'diverse'),\n",
              " ('immersing', 'array'),\n",
              " ('diverse', 'events'),\n",
              " ('diverse', 'immersing'),\n",
              " ('diverse', 'array'),\n",
              " ('diverse', 'interests'),\n",
              " ('array', 'immersing'),\n",
              " ('array', 'diverse'),\n",
              " ('array', 'interests'),\n",
              " ('array', 'passions'),\n",
              " ('interests', 'diverse'),\n",
              " ('interests', 'array'),\n",
              " ('interests', 'passions'),\n",
              " ('interests', ''),\n",
              " ('passions', 'array'),\n",
              " ('passions', 'interests'),\n",
              " ('passions', ''),\n",
              " ('', 'interests'),\n",
              " ('', 'passions'),\n",
              " ('late', 'night'),\n",
              " ('late', 'study'),\n",
              " ('night', 'late'),\n",
              " ('night', 'study'),\n",
              " ('night', 'sessions'),\n",
              " ('study', 'late'),\n",
              " ('study', 'night'),\n",
              " ('study', 'sessions'),\n",
              " ('study', 'balanced'),\n",
              " ('sessions', 'night'),\n",
              " ('sessions', 'study'),\n",
              " ('sessions', 'balanced'),\n",
              " ('sessions', 'moments'),\n",
              " ('balanced', 'study'),\n",
              " ('balanced', 'sessions'),\n",
              " ('balanced', 'moments'),\n",
              " ('balanced', 'relaxation'),\n",
              " ('moments', 'sessions'),\n",
              " ('moments', 'balanced'),\n",
              " ('moments', 'relaxation'),\n",
              " ('moments', 'unwind'),\n",
              " ('relaxation', 'balanced'),\n",
              " ('relaxation', 'moments'),\n",
              " ('relaxation', 'unwind'),\n",
              " ('relaxation', 'watch'),\n",
              " ('unwind', 'moments'),\n",
              " ('unwind', 'relaxation'),\n",
              " ('unwind', 'watch'),\n",
              " ('unwind', 'movies'),\n",
              " ('watch', 'relaxation'),\n",
              " ('watch', 'unwind'),\n",
              " ('watch', 'movies'),\n",
              " ('watch', 'share'),\n",
              " ('movies', 'unwind'),\n",
              " ('movies', 'watch'),\n",
              " ('movies', 'share'),\n",
              " ('movies', 'laughter'),\n",
              " ('share', 'watch'),\n",
              " ('share', 'movies'),\n",
              " ('share', 'laughter'),\n",
              " ('share', 'roommates'),\n",
              " ('laughter', 'movies'),\n",
              " ('laughter', 'share'),\n",
              " ('laughter', 'roommates'),\n",
              " ('laughter', ''),\n",
              " ('roommates', 'share'),\n",
              " ('roommates', 'laughter'),\n",
              " ('roommates', ''),\n",
              " ('', 'laughter'),\n",
              " ('', 'roommates'),\n",
              " ('pursuit', 'knowledge'),\n",
              " ('pursuit', 'intertwined'),\n",
              " ('knowledge', 'pursuit'),\n",
              " ('knowledge', 'intertwined'),\n",
              " ('knowledge', 'pursuit'),\n",
              " ('intertwined', 'pursuit'),\n",
              " ('intertwined', 'knowledge'),\n",
              " ('intertwined', 'pursuit'),\n",
              " ('intertwined', 'self'),\n",
              " ('pursuit', 'knowledge'),\n",
              " ('pursuit', 'intertwined'),\n",
              " ('pursuit', 'self'),\n",
              " ('pursuit', 'expression'),\n",
              " ('self', 'intertwined'),\n",
              " ('self', 'pursuit'),\n",
              " ('self', 'expression'),\n",
              " ('self', 'students'),\n",
              " ('expression', 'pursuit'),\n",
              " ('expression', 'self'),\n",
              " ('expression', 'students'),\n",
              " ('expression', 'often'),\n",
              " ('students', 'self'),\n",
              " ('students', 'expression'),\n",
              " ('students', 'often'),\n",
              " ('students', 'discover'),\n",
              " ('often', 'expression'),\n",
              " ('often', 'students'),\n",
              " ('often', 'discover'),\n",
              " ('often', 'true'),\n",
              " ('discover', 'students'),\n",
              " ('discover', 'often'),\n",
              " ('discover', 'true'),\n",
              " ('discover', 'interests'),\n",
              " ('true', 'often'),\n",
              " ('true', 'discover'),\n",
              " ('true', 'interests'),\n",
              " ('true', 'values'),\n",
              " ('interests', 'discover'),\n",
              " ('interests', 'true'),\n",
              " ('interests', 'values'),\n",
              " ('interests', 'career'),\n",
              " ('values', 'true'),\n",
              " ('values', 'interests'),\n",
              " ('values', 'career'),\n",
              " ('values', 'aspirations'),\n",
              " ('career', 'interests'),\n",
              " ('career', 'values'),\n",
              " ('career', 'aspirations'),\n",
              " ('career', 'transformative'),\n",
              " ('aspirations', 'values'),\n",
              " ('aspirations', 'career'),\n",
              " ('aspirations', 'transformative'),\n",
              " ('aspirations', 'phase'),\n",
              " ('transformative', 'career'),\n",
              " ('transformative', 'aspirations'),\n",
              " ('transformative', 'phase'),\n",
              " ('transformative', ''),\n",
              " ('phase', 'aspirations'),\n",
              " ('phase', 'transformative'),\n",
              " ('phase', ''),\n",
              " ('', 'transformative'),\n",
              " ('', 'phase'),\n",
              " ('time', 'challenges'),\n",
              " ('time', 'triumphs'),\n",
              " ('challenges', 'time'),\n",
              " ('challenges', 'triumphs'),\n",
              " ('challenges', 'period'),\n",
              " ('triumphs', 'time'),\n",
              " ('triumphs', 'challenges'),\n",
              " ('triumphs', 'period'),\n",
              " ('triumphs', 'shapes'),\n",
              " ('period', 'challenges'),\n",
              " ('period', 'triumphs'),\n",
              " ('period', 'shapes'),\n",
              " ('period', 'future'),\n",
              " ('shapes', 'triumphs'),\n",
              " ('shapes', 'period'),\n",
              " ('shapes', 'future'),\n",
              " ('shapes', 'leaders'),\n",
              " ('future', 'period'),\n",
              " ('future', 'shapes'),\n",
              " ('future', 'leaders'),\n",
              " ('future', 'thinkers'),\n",
              " ('leaders', 'shapes'),\n",
              " ('leaders', 'future'),\n",
              " ('leaders', 'thinkers'),\n",
              " ('leaders', 'innovators'),\n",
              " ('thinkers', 'future'),\n",
              " ('thinkers', 'leaders'),\n",
              " ('thinkers', 'innovators'),\n",
              " ('thinkers', ''),\n",
              " ('innovators', 'leaders'),\n",
              " ('innovators', 'thinkers'),\n",
              " ('innovators', ''),\n",
              " ('', 'thinkers'),\n",
              " ('', 'innovators')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NgkRNBm4GpZ"
      },
      "source": [
        "#defining a method for one-hot encoding\n",
        "def to_one_hot_encoding(data_point_index):\n",
        "\n",
        "    one_hot_encoding=np.zeros(len(unique_words))\n",
        "    one_hot_encoding[data_point_index]=1\n",
        "    return one_hot_encoding"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK0M9JJz4LtJ"
      },
      "source": [
        "#storing one hot encoded values of the data generated in X_train and Y_train where the index of the 1 is the value of the word in the dictionary\n",
        "def one_hot_for_skip_gram(word2int, data):\n",
        "    samples=len(data)\n",
        "    vocab=len(word2int.keys())\n",
        "    X=[]\n",
        "    Y=[]\n",
        "    for i in range(0,samples):\n",
        "      X+=[to_one_hot_encoding(word2int[data[i][0]])]\n",
        "      Y+=[to_one_hot_encoding(word2int[data[i][1]])]\n",
        "    X=np.array(X)\n",
        "    Y=np.array(Y)\n",
        "    return X, Y\n",
        "\n",
        "X_train,Y_train = one_hot_for_skip_gram(word2int, data)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cpHy7rL4Nzi"
      },
      "source": [
        "#importing  keras and all the required components for the model\n",
        "import keras\n",
        "\n",
        "from keras.layers import Input,Dense\n",
        "from keras.models import Model, Sequential\n",
        "from keras import optimizers"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TFbRRps4R8A"
      },
      "source": [
        "\n",
        "#creating the model as we will find the word vectors of each word from the model. We define the model as such as that the length of the word vectors is the number of neurons in the last hidden layer.\n",
        "def create_model():\n",
        "    input_layer=Input(shape=(len(unique_words),))\n",
        "    hidden_layer=Dense(11)(input_layer)\n",
        "    output_layer=Dense(len(unique_words),activation='softmax')(hidden_layer)\n",
        "    model=Model([input_layer],[output_layer])\n",
        "    model.compile(optimizer='Adam',loss='categorical_crossentropy')\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XNZdy5k4Vlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38d6b6d-6602-46dc-8c9e-b8cd6464db97"
      },
      "source": [
        "#creating the model and naming it as 'model'\n",
        "model = create_model()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 95)]              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 11)                1056      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 95)                1140      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,196\n",
            "Trainable params: 2,196\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUC9o7By4YxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1cdf6b-072e-4351-e7bf-adfc17de378d"
      },
      "source": [
        "#keeping a copy of the model\n",
        "import copy\n",
        "model_before = copy.copy(model)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzhp1xQl4bj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18740c93-b7c0-4f8b-a3cd-4e3b492c05c2"
      },
      "source": [
        "#Model fitting is creating that simplified representation in a way that can generally be used successfully given new data.\n",
        "model.fit(X_train, Y_train, epochs = 1000, batch_size = 200)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "3/3 [==============================] - 1s 7ms/step - loss: 4.5560\n",
            "Epoch 2/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 4.5530\n",
            "Epoch 3/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.5506\n",
            "Epoch 4/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.5484\n",
            "Epoch 5/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.5462\n",
            "Epoch 6/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5442\n",
            "Epoch 7/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5422\n",
            "Epoch 8/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.5402\n",
            "Epoch 9/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5384\n",
            "Epoch 10/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5365\n",
            "Epoch 11/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.5347\n",
            "Epoch 12/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5330\n",
            "Epoch 13/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.5312\n",
            "Epoch 14/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.5295\n",
            "Epoch 15/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5278\n",
            "Epoch 16/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.5262\n",
            "Epoch 17/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5245\n",
            "Epoch 18/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.5228\n",
            "Epoch 19/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.5212\n",
            "Epoch 20/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5196\n",
            "Epoch 21/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5179\n",
            "Epoch 22/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5163\n",
            "Epoch 23/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5147\n",
            "Epoch 24/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.5131\n",
            "Epoch 25/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5115\n",
            "Epoch 26/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5099\n",
            "Epoch 27/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5084\n",
            "Epoch 28/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.5068\n",
            "Epoch 29/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5052\n",
            "Epoch 30/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5036\n",
            "Epoch 31/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5020\n",
            "Epoch 32/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.5004\n",
            "Epoch 33/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4988\n",
            "Epoch 34/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4972\n",
            "Epoch 35/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4957\n",
            "Epoch 36/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4941\n",
            "Epoch 37/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4926\n",
            "Epoch 38/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4910\n",
            "Epoch 39/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4894\n",
            "Epoch 40/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.4878\n",
            "Epoch 41/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4862\n",
            "Epoch 42/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4846\n",
            "Epoch 43/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4830\n",
            "Epoch 44/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4815\n",
            "Epoch 45/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4799\n",
            "Epoch 46/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4784\n",
            "Epoch 47/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4769\n",
            "Epoch 48/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4753\n",
            "Epoch 49/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.4738\n",
            "Epoch 50/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4722\n",
            "Epoch 51/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.4707\n",
            "Epoch 52/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4691\n",
            "Epoch 53/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.4675\n",
            "Epoch 54/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4660\n",
            "Epoch 55/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4644\n",
            "Epoch 56/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4628\n",
            "Epoch 57/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4611\n",
            "Epoch 58/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4595\n",
            "Epoch 59/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4578\n",
            "Epoch 60/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4561\n",
            "Epoch 61/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4543\n",
            "Epoch 62/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4526\n",
            "Epoch 63/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4507\n",
            "Epoch 64/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4489\n",
            "Epoch 65/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4469\n",
            "Epoch 66/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.4450\n",
            "Epoch 67/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4431\n",
            "Epoch 68/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4412\n",
            "Epoch 69/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4392\n",
            "Epoch 70/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4373\n",
            "Epoch 71/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4353\n",
            "Epoch 72/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4334\n",
            "Epoch 73/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4313\n",
            "Epoch 74/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4294\n",
            "Epoch 75/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4273\n",
            "Epoch 76/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4253\n",
            "Epoch 77/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4233\n",
            "Epoch 78/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4213\n",
            "Epoch 79/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4192\n",
            "Epoch 80/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4172\n",
            "Epoch 81/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4151\n",
            "Epoch 82/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4131\n",
            "Epoch 83/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.4110\n",
            "Epoch 84/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4088\n",
            "Epoch 85/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4067\n",
            "Epoch 86/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4046\n",
            "Epoch 87/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4024\n",
            "Epoch 88/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4003\n",
            "Epoch 89/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3981\n",
            "Epoch 90/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3960\n",
            "Epoch 91/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3938\n",
            "Epoch 92/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.3917\n",
            "Epoch 93/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3895\n",
            "Epoch 94/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3873\n",
            "Epoch 95/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.3850\n",
            "Epoch 96/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.3827\n",
            "Epoch 97/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3805\n",
            "Epoch 98/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.3782\n",
            "Epoch 99/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3759\n",
            "Epoch 100/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.3736\n",
            "Epoch 101/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3712\n",
            "Epoch 102/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.3689\n",
            "Epoch 103/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3664\n",
            "Epoch 104/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3640\n",
            "Epoch 105/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.3615\n",
            "Epoch 106/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3589\n",
            "Epoch 107/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.3563\n",
            "Epoch 108/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3537\n",
            "Epoch 109/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.3511\n",
            "Epoch 110/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3485\n",
            "Epoch 111/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3460\n",
            "Epoch 112/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.3432\n",
            "Epoch 113/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3406\n",
            "Epoch 114/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3379\n",
            "Epoch 115/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.3351\n",
            "Epoch 116/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.3324\n",
            "Epoch 117/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3296\n",
            "Epoch 118/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3268\n",
            "Epoch 119/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 4.3240\n",
            "Epoch 120/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3212\n",
            "Epoch 121/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3184\n",
            "Epoch 122/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3156\n",
            "Epoch 123/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.3128\n",
            "Epoch 124/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3100\n",
            "Epoch 125/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3072\n",
            "Epoch 126/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.3044\n",
            "Epoch 127/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.3016\n",
            "Epoch 128/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.2987\n",
            "Epoch 129/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2958\n",
            "Epoch 130/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2927\n",
            "Epoch 131/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.2897\n",
            "Epoch 132/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.2866\n",
            "Epoch 133/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.2836\n",
            "Epoch 134/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.2804\n",
            "Epoch 135/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2772\n",
            "Epoch 136/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2740\n",
            "Epoch 137/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.2709\n",
            "Epoch 138/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.2677\n",
            "Epoch 139/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.2645\n",
            "Epoch 140/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2613\n",
            "Epoch 141/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 4.2581\n",
            "Epoch 142/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.2549\n",
            "Epoch 143/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2517\n",
            "Epoch 144/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.2485\n",
            "Epoch 145/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2454\n",
            "Epoch 146/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.2423\n",
            "Epoch 147/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.2391\n",
            "Epoch 148/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2359\n",
            "Epoch 149/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.2327\n",
            "Epoch 150/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2293\n",
            "Epoch 151/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2259\n",
            "Epoch 152/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2224\n",
            "Epoch 153/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2189\n",
            "Epoch 154/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2156\n",
            "Epoch 155/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.2122\n",
            "Epoch 156/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.2087\n",
            "Epoch 157/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.2055\n",
            "Epoch 158/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2020\n",
            "Epoch 159/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.1985\n",
            "Epoch 160/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.1950\n",
            "Epoch 161/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1916\n",
            "Epoch 162/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1881\n",
            "Epoch 163/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1847\n",
            "Epoch 164/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1812\n",
            "Epoch 165/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1777\n",
            "Epoch 166/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1741\n",
            "Epoch 167/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1704\n",
            "Epoch 168/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1667\n",
            "Epoch 169/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.1630\n",
            "Epoch 170/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.1594\n",
            "Epoch 171/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.1556\n",
            "Epoch 172/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 4.1519\n",
            "Epoch 173/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1482\n",
            "Epoch 174/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1444\n",
            "Epoch 175/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1406\n",
            "Epoch 176/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1368\n",
            "Epoch 177/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1330\n",
            "Epoch 178/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1292\n",
            "Epoch 179/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1252\n",
            "Epoch 180/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.1213\n",
            "Epoch 181/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1173\n",
            "Epoch 182/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1135\n",
            "Epoch 183/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 4.1096\n",
            "Epoch 184/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1056\n",
            "Epoch 185/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.1015\n",
            "Epoch 186/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0973\n",
            "Epoch 187/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.0930\n",
            "Epoch 188/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0889\n",
            "Epoch 189/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0848\n",
            "Epoch 190/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0806\n",
            "Epoch 191/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0764\n",
            "Epoch 192/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0724\n",
            "Epoch 193/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.0683\n",
            "Epoch 194/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0642\n",
            "Epoch 195/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0602\n",
            "Epoch 196/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.0561\n",
            "Epoch 197/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0520\n",
            "Epoch 198/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0478\n",
            "Epoch 199/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0435\n",
            "Epoch 200/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0392\n",
            "Epoch 201/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.0348\n",
            "Epoch 202/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0304\n",
            "Epoch 203/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.0260\n",
            "Epoch 204/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0216\n",
            "Epoch 205/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.0172\n",
            "Epoch 206/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0130\n",
            "Epoch 207/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0086\n",
            "Epoch 208/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0044\n",
            "Epoch 209/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.0002\n",
            "Epoch 210/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.9958\n",
            "Epoch 211/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9914\n",
            "Epoch 212/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9871\n",
            "Epoch 213/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9827\n",
            "Epoch 214/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.9782\n",
            "Epoch 215/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.9737\n",
            "Epoch 216/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9691\n",
            "Epoch 217/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.9646\n",
            "Epoch 218/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9602\n",
            "Epoch 219/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.9557\n",
            "Epoch 220/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.9511\n",
            "Epoch 221/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9466\n",
            "Epoch 222/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9420\n",
            "Epoch 223/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9374\n",
            "Epoch 224/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.9328\n",
            "Epoch 225/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9282\n",
            "Epoch 226/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9234\n",
            "Epoch 227/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.9188\n",
            "Epoch 228/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 3.9141\n",
            "Epoch 229/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.9095\n",
            "Epoch 230/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.9050\n",
            "Epoch 231/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9003\n",
            "Epoch 232/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.8957\n",
            "Epoch 233/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8912\n",
            "Epoch 234/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.8866\n",
            "Epoch 235/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.8821\n",
            "Epoch 236/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8775\n",
            "Epoch 237/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8729\n",
            "Epoch 238/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8683\n",
            "Epoch 239/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8636\n",
            "Epoch 240/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8590\n",
            "Epoch 241/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8543\n",
            "Epoch 242/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.8495\n",
            "Epoch 243/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.8448\n",
            "Epoch 244/1000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 3.8399\n",
            "Epoch 245/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.8350\n",
            "Epoch 246/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.8301\n",
            "Epoch 247/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8252\n",
            "Epoch 248/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8203\n",
            "Epoch 249/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.8155\n",
            "Epoch 250/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8106\n",
            "Epoch 251/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8059\n",
            "Epoch 252/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8009\n",
            "Epoch 253/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.7961\n",
            "Epoch 254/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.7912\n",
            "Epoch 255/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7864\n",
            "Epoch 256/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7816\n",
            "Epoch 257/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7767\n",
            "Epoch 258/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7719\n",
            "Epoch 259/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.7670\n",
            "Epoch 260/1000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 3.7621\n",
            "Epoch 261/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7572\n",
            "Epoch 262/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7523\n",
            "Epoch 263/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.7475\n",
            "Epoch 264/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7427\n",
            "Epoch 265/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 3.7378\n",
            "Epoch 266/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 3.7328\n",
            "Epoch 267/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7279\n",
            "Epoch 268/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.7229\n",
            "Epoch 269/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.7178\n",
            "Epoch 270/1000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 3.7127\n",
            "Epoch 271/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7077\n",
            "Epoch 272/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 3.7026\n",
            "Epoch 273/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.6975\n",
            "Epoch 274/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.6925\n",
            "Epoch 275/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.6875\n",
            "Epoch 276/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.6823\n",
            "Epoch 277/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.6772\n",
            "Epoch 278/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.6720\n",
            "Epoch 279/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.6669\n",
            "Epoch 280/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.6617\n",
            "Epoch 281/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.6564\n",
            "Epoch 282/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.6512\n",
            "Epoch 283/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.6461\n",
            "Epoch 284/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 3.6409\n",
            "Epoch 285/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.6359\n",
            "Epoch 286/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.6307\n",
            "Epoch 287/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.6255\n",
            "Epoch 288/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.6203\n",
            "Epoch 289/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.6151\n",
            "Epoch 290/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.6100\n",
            "Epoch 291/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.6048\n",
            "Epoch 292/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.5998\n",
            "Epoch 293/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.5946\n",
            "Epoch 294/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.5895\n",
            "Epoch 295/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.5843\n",
            "Epoch 296/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.5792\n",
            "Epoch 297/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.5740\n",
            "Epoch 298/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.5689\n",
            "Epoch 299/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.5637\n",
            "Epoch 300/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.5585\n",
            "Epoch 301/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.5535\n",
            "Epoch 302/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.5483\n",
            "Epoch 303/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.5430\n",
            "Epoch 304/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.5379\n",
            "Epoch 305/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.5329\n",
            "Epoch 306/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.5279\n",
            "Epoch 307/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.5227\n",
            "Epoch 308/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.5175\n",
            "Epoch 309/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.5125\n",
            "Epoch 310/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 3.5073\n",
            "Epoch 311/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.5022\n",
            "Epoch 312/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4970\n",
            "Epoch 313/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.4918\n",
            "Epoch 314/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.4866\n",
            "Epoch 315/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4814\n",
            "Epoch 316/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.4762\n",
            "Epoch 317/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4710\n",
            "Epoch 318/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4659\n",
            "Epoch 319/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.4608\n",
            "Epoch 320/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.4556\n",
            "Epoch 321/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.4504\n",
            "Epoch 322/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4451\n",
            "Epoch 323/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4401\n",
            "Epoch 324/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4350\n",
            "Epoch 325/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.4298\n",
            "Epoch 326/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.4246\n",
            "Epoch 327/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4195\n",
            "Epoch 328/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4143\n",
            "Epoch 329/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4091\n",
            "Epoch 330/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4040\n",
            "Epoch 331/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.3988\n",
            "Epoch 332/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.3938\n",
            "Epoch 333/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3886\n",
            "Epoch 334/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3835\n",
            "Epoch 335/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3783\n",
            "Epoch 336/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3732\n",
            "Epoch 337/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.3681\n",
            "Epoch 338/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.3629\n",
            "Epoch 339/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.3577\n",
            "Epoch 340/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.3526\n",
            "Epoch 341/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.3473\n",
            "Epoch 342/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3422\n",
            "Epoch 343/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3371\n",
            "Epoch 344/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3318\n",
            "Epoch 345/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.3267\n",
            "Epoch 346/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.3215\n",
            "Epoch 347/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.3163\n",
            "Epoch 348/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.3110\n",
            "Epoch 349/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.3060\n",
            "Epoch 350/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3009\n",
            "Epoch 351/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.2958\n",
            "Epoch 352/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.2909\n",
            "Epoch 353/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 3.2861\n",
            "Epoch 354/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.2809\n",
            "Epoch 355/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.2758\n",
            "Epoch 356/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.2708\n",
            "Epoch 357/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.2656\n",
            "Epoch 358/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.2607\n",
            "Epoch 359/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.2556\n",
            "Epoch 360/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.2505\n",
            "Epoch 361/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 3.2453\n",
            "Epoch 362/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.2402\n",
            "Epoch 363/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.2353\n",
            "Epoch 364/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.2302\n",
            "Epoch 365/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.2253\n",
            "Epoch 366/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.2204\n",
            "Epoch 367/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.2153\n",
            "Epoch 368/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.2103\n",
            "Epoch 369/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.2054\n",
            "Epoch 370/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.2004\n",
            "Epoch 371/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1955\n",
            "Epoch 372/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1904\n",
            "Epoch 373/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.1856\n",
            "Epoch 374/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1807\n",
            "Epoch 375/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1758\n",
            "Epoch 376/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1710\n",
            "Epoch 377/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1662\n",
            "Epoch 378/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1614\n",
            "Epoch 379/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1566\n",
            "Epoch 380/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1518\n",
            "Epoch 381/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1470\n",
            "Epoch 382/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1423\n",
            "Epoch 383/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.1376\n",
            "Epoch 384/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1328\n",
            "Epoch 385/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.1281\n",
            "Epoch 386/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1234\n",
            "Epoch 387/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.1187\n",
            "Epoch 388/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.1140\n",
            "Epoch 389/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.1091\n",
            "Epoch 390/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.1043\n",
            "Epoch 391/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0993\n",
            "Epoch 392/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.0945\n",
            "Epoch 393/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.0898\n",
            "Epoch 394/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.0850\n",
            "Epoch 395/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0801\n",
            "Epoch 396/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.0754\n",
            "Epoch 397/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0708\n",
            "Epoch 398/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.0660\n",
            "Epoch 399/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0613\n",
            "Epoch 400/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0566\n",
            "Epoch 401/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0521\n",
            "Epoch 402/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0474\n",
            "Epoch 403/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0429\n",
            "Epoch 404/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0384\n",
            "Epoch 405/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.0337\n",
            "Epoch 406/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.0291\n",
            "Epoch 407/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.0245\n",
            "Epoch 408/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0199\n",
            "Epoch 409/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0155\n",
            "Epoch 410/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.0110\n",
            "Epoch 411/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.0065\n",
            "Epoch 412/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.0020\n",
            "Epoch 413/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.9977\n",
            "Epoch 414/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.9931\n",
            "Epoch 415/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.9887\n",
            "Epoch 416/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.9843\n",
            "Epoch 417/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.9799\n",
            "Epoch 418/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.9755\n",
            "Epoch 419/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.9710\n",
            "Epoch 420/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.9664\n",
            "Epoch 421/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.9621\n",
            "Epoch 422/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.9576\n",
            "Epoch 423/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.9531\n",
            "Epoch 424/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.9487\n",
            "Epoch 425/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.9443\n",
            "Epoch 426/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.9399\n",
            "Epoch 427/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.9356\n",
            "Epoch 428/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.9314\n",
            "Epoch 429/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.9271\n",
            "Epoch 430/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.9229\n",
            "Epoch 431/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.9187\n",
            "Epoch 432/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.9144\n",
            "Epoch 433/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.9103\n",
            "Epoch 434/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.9061\n",
            "Epoch 435/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.9019\n",
            "Epoch 436/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.8978\n",
            "Epoch 437/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.8936\n",
            "Epoch 438/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8895\n",
            "Epoch 439/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.8854\n",
            "Epoch 440/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8814\n",
            "Epoch 441/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.8772\n",
            "Epoch 442/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.8733\n",
            "Epoch 443/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8691\n",
            "Epoch 444/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.8651\n",
            "Epoch 445/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.8610\n",
            "Epoch 446/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.8570\n",
            "Epoch 447/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8530\n",
            "Epoch 448/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8491\n",
            "Epoch 449/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8452\n",
            "Epoch 450/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.8412\n",
            "Epoch 451/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.8372\n",
            "Epoch 452/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.8333\n",
            "Epoch 453/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.8294\n",
            "Epoch 454/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8255\n",
            "Epoch 455/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8215\n",
            "Epoch 456/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.8177\n",
            "Epoch 457/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8138\n",
            "Epoch 458/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8100\n",
            "Epoch 459/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8060\n",
            "Epoch 460/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.8024\n",
            "Epoch 461/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7984\n",
            "Epoch 462/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7945\n",
            "Epoch 463/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.7907\n",
            "Epoch 464/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.7868\n",
            "Epoch 465/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7829\n",
            "Epoch 466/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7792\n",
            "Epoch 467/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7754\n",
            "Epoch 468/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.7717\n",
            "Epoch 469/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.7680\n",
            "Epoch 470/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7642\n",
            "Epoch 471/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.7607\n",
            "Epoch 472/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7571\n",
            "Epoch 473/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.7535\n",
            "Epoch 474/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7498\n",
            "Epoch 475/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.7463\n",
            "Epoch 476/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.7428\n",
            "Epoch 477/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7393\n",
            "Epoch 478/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7357\n",
            "Epoch 479/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7322\n",
            "Epoch 480/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7287\n",
            "Epoch 481/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7252\n",
            "Epoch 482/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7217\n",
            "Epoch 483/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.7183\n",
            "Epoch 484/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7148\n",
            "Epoch 485/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.7112\n",
            "Epoch 486/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7077\n",
            "Epoch 487/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.7043\n",
            "Epoch 488/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.7007\n",
            "Epoch 489/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.6971\n",
            "Epoch 490/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.6937\n",
            "Epoch 491/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.6904\n",
            "Epoch 492/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6871\n",
            "Epoch 493/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6839\n",
            "Epoch 494/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.6805\n",
            "Epoch 495/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6774\n",
            "Epoch 496/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.6740\n",
            "Epoch 497/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.6709\n",
            "Epoch 498/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6677\n",
            "Epoch 499/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6643\n",
            "Epoch 500/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.6611\n",
            "Epoch 501/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6578\n",
            "Epoch 502/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6546\n",
            "Epoch 503/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6513\n",
            "Epoch 504/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6481\n",
            "Epoch 505/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.6447\n",
            "Epoch 506/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6414\n",
            "Epoch 507/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6383\n",
            "Epoch 508/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.6349\n",
            "Epoch 509/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6316\n",
            "Epoch 510/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6284\n",
            "Epoch 511/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6253\n",
            "Epoch 512/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.6221\n",
            "Epoch 513/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6188\n",
            "Epoch 514/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6155\n",
            "Epoch 515/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.6123\n",
            "Epoch 516/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6091\n",
            "Epoch 517/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.6059\n",
            "Epoch 518/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.6029\n",
            "Epoch 519/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5998\n",
            "Epoch 520/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5966\n",
            "Epoch 521/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5935\n",
            "Epoch 522/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5905\n",
            "Epoch 523/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5875\n",
            "Epoch 524/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5845\n",
            "Epoch 525/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.5813\n",
            "Epoch 526/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5783\n",
            "Epoch 527/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5754\n",
            "Epoch 528/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5725\n",
            "Epoch 529/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.5695\n",
            "Epoch 530/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5666\n",
            "Epoch 531/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5638\n",
            "Epoch 532/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5608\n",
            "Epoch 533/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5579\n",
            "Epoch 534/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5549\n",
            "Epoch 535/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5520\n",
            "Epoch 536/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5490\n",
            "Epoch 537/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.5460\n",
            "Epoch 538/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.5431\n",
            "Epoch 539/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5403\n",
            "Epoch 540/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5374\n",
            "Epoch 541/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5345\n",
            "Epoch 542/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5317\n",
            "Epoch 543/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5289\n",
            "Epoch 544/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5262\n",
            "Epoch 545/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5235\n",
            "Epoch 546/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5207\n",
            "Epoch 547/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5179\n",
            "Epoch 548/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5151\n",
            "Epoch 549/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5121\n",
            "Epoch 550/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5094\n",
            "Epoch 551/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.5066\n",
            "Epoch 552/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.5039\n",
            "Epoch 553/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.5012\n",
            "Epoch 554/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.4985\n",
            "Epoch 555/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4958\n",
            "Epoch 556/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.4932\n",
            "Epoch 557/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.4906\n",
            "Epoch 558/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4879\n",
            "Epoch 559/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4853\n",
            "Epoch 560/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4827\n",
            "Epoch 561/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4800\n",
            "Epoch 562/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4775\n",
            "Epoch 563/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4749\n",
            "Epoch 564/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4725\n",
            "Epoch 565/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4698\n",
            "Epoch 566/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.4673\n",
            "Epoch 567/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.4651\n",
            "Epoch 568/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4624\n",
            "Epoch 569/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4600\n",
            "Epoch 570/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4574\n",
            "Epoch 571/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4548\n",
            "Epoch 572/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4522\n",
            "Epoch 573/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4496\n",
            "Epoch 574/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4471\n",
            "Epoch 575/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4446\n",
            "Epoch 576/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4422\n",
            "Epoch 577/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.4397\n",
            "Epoch 578/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4372\n",
            "Epoch 579/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4348\n",
            "Epoch 580/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4322\n",
            "Epoch 581/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4299\n",
            "Epoch 582/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4274\n",
            "Epoch 583/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4251\n",
            "Epoch 584/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4228\n",
            "Epoch 585/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4204\n",
            "Epoch 586/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4181\n",
            "Epoch 587/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4157\n",
            "Epoch 588/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.4132\n",
            "Epoch 589/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4108\n",
            "Epoch 590/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4085\n",
            "Epoch 591/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4062\n",
            "Epoch 592/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4039\n",
            "Epoch 593/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4017\n",
            "Epoch 594/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3994\n",
            "Epoch 595/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3971\n",
            "Epoch 596/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3949\n",
            "Epoch 597/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3927\n",
            "Epoch 598/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.3905\n",
            "Epoch 599/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.3883\n",
            "Epoch 600/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3861\n",
            "Epoch 601/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3840\n",
            "Epoch 602/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3820\n",
            "Epoch 603/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3798\n",
            "Epoch 604/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.3777\n",
            "Epoch 605/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3755\n",
            "Epoch 606/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.3733\n",
            "Epoch 607/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3712\n",
            "Epoch 608/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.3691\n",
            "Epoch 609/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3669\n",
            "Epoch 610/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.3649\n",
            "Epoch 611/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3629\n",
            "Epoch 612/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3609\n",
            "Epoch 613/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.3587\n",
            "Epoch 614/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.3565\n",
            "Epoch 615/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3546\n",
            "Epoch 616/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3524\n",
            "Epoch 617/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3501\n",
            "Epoch 618/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3480\n",
            "Epoch 619/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3460\n",
            "Epoch 620/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3440\n",
            "Epoch 621/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3421\n",
            "Epoch 622/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3401\n",
            "Epoch 623/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3380\n",
            "Epoch 624/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3359\n",
            "Epoch 625/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.3339\n",
            "Epoch 626/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3318\n",
            "Epoch 627/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3298\n",
            "Epoch 628/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.3279\n",
            "Epoch 629/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3257\n",
            "Epoch 630/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3239\n",
            "Epoch 631/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.3219\n",
            "Epoch 632/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3200\n",
            "Epoch 633/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3181\n",
            "Epoch 634/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3161\n",
            "Epoch 635/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.3142\n",
            "Epoch 636/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3123\n",
            "Epoch 637/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3105\n",
            "Epoch 638/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.3086\n",
            "Epoch 639/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.3067\n",
            "Epoch 640/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3049\n",
            "Epoch 641/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.3030\n",
            "Epoch 642/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3012\n",
            "Epoch 643/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.2993\n",
            "Epoch 644/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2973\n",
            "Epoch 645/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.2956\n",
            "Epoch 646/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.2937\n",
            "Epoch 647/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.2920\n",
            "Epoch 648/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2901\n",
            "Epoch 649/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2884\n",
            "Epoch 650/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2869\n",
            "Epoch 651/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2850\n",
            "Epoch 652/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.2833\n",
            "Epoch 653/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2815\n",
            "Epoch 654/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2799\n",
            "Epoch 655/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2780\n",
            "Epoch 656/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2762\n",
            "Epoch 657/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2743\n",
            "Epoch 658/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2725\n",
            "Epoch 659/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.2706\n",
            "Epoch 660/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.2688\n",
            "Epoch 661/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2669\n",
            "Epoch 662/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.2650\n",
            "Epoch 663/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2633\n",
            "Epoch 664/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2616\n",
            "Epoch 665/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2600\n",
            "Epoch 666/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.2583\n",
            "Epoch 667/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.2565\n",
            "Epoch 668/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2547\n",
            "Epoch 669/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2530\n",
            "Epoch 670/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2513\n",
            "Epoch 671/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2495\n",
            "Epoch 672/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.2477\n",
            "Epoch 673/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2461\n",
            "Epoch 674/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2444\n",
            "Epoch 675/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.2428\n",
            "Epoch 676/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.2410\n",
            "Epoch 677/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.2395\n",
            "Epoch 678/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.2377\n",
            "Epoch 679/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.2361\n",
            "Epoch 680/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.2343\n",
            "Epoch 681/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2328\n",
            "Epoch 682/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2312\n",
            "Epoch 683/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2298\n",
            "Epoch 684/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2281\n",
            "Epoch 685/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2266\n",
            "Epoch 686/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2251\n",
            "Epoch 687/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2235\n",
            "Epoch 688/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2220\n",
            "Epoch 689/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2204\n",
            "Epoch 690/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2188\n",
            "Epoch 691/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2171\n",
            "Epoch 692/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2155\n",
            "Epoch 693/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.2139\n",
            "Epoch 694/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2123\n",
            "Epoch 695/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2108\n",
            "Epoch 696/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2093\n",
            "Epoch 697/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2078\n",
            "Epoch 698/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2061\n",
            "Epoch 699/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2047\n",
            "Epoch 700/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.2034\n",
            "Epoch 701/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.2019\n",
            "Epoch 702/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.2004\n",
            "Epoch 703/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1990\n",
            "Epoch 704/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1976\n",
            "Epoch 705/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1962\n",
            "Epoch 706/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1947\n",
            "Epoch 707/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1935\n",
            "Epoch 708/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1920\n",
            "Epoch 709/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1906\n",
            "Epoch 710/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1890\n",
            "Epoch 711/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1876\n",
            "Epoch 712/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1862\n",
            "Epoch 713/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1848\n",
            "Epoch 714/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1835\n",
            "Epoch 715/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1821\n",
            "Epoch 716/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1806\n",
            "Epoch 717/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1793\n",
            "Epoch 718/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1778\n",
            "Epoch 719/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.1763\n",
            "Epoch 720/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1748\n",
            "Epoch 721/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1736\n",
            "Epoch 722/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1721\n",
            "Epoch 723/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1707\n",
            "Epoch 724/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1694\n",
            "Epoch 725/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1678\n",
            "Epoch 726/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1665\n",
            "Epoch 727/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1652\n",
            "Epoch 728/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1639\n",
            "Epoch 729/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1626\n",
            "Epoch 730/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1612\n",
            "Epoch 731/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1599\n",
            "Epoch 732/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1586\n",
            "Epoch 733/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1574\n",
            "Epoch 734/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1560\n",
            "Epoch 735/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1547\n",
            "Epoch 736/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1535\n",
            "Epoch 737/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1521\n",
            "Epoch 738/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1508\n",
            "Epoch 739/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1496\n",
            "Epoch 740/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1483\n",
            "Epoch 741/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1469\n",
            "Epoch 742/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1457\n",
            "Epoch 743/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1444\n",
            "Epoch 744/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.1434\n",
            "Epoch 745/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1422\n",
            "Epoch 746/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1411\n",
            "Epoch 747/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1398\n",
            "Epoch 748/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1388\n",
            "Epoch 749/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1375\n",
            "Epoch 750/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1362\n",
            "Epoch 751/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1350\n",
            "Epoch 752/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1338\n",
            "Epoch 753/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1325\n",
            "Epoch 754/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1312\n",
            "Epoch 755/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1301\n",
            "Epoch 756/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1289\n",
            "Epoch 757/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1277\n",
            "Epoch 758/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1267\n",
            "Epoch 759/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1255\n",
            "Epoch 760/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1242\n",
            "Epoch 761/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1230\n",
            "Epoch 762/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1217\n",
            "Epoch 763/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1206\n",
            "Epoch 764/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1194\n",
            "Epoch 765/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1183\n",
            "Epoch 766/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1170\n",
            "Epoch 767/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1159\n",
            "Epoch 768/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1147\n",
            "Epoch 769/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1136\n",
            "Epoch 770/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1124\n",
            "Epoch 771/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1112\n",
            "Epoch 772/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1100\n",
            "Epoch 773/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1088\n",
            "Epoch 774/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1078\n",
            "Epoch 775/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.1067\n",
            "Epoch 776/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1056\n",
            "Epoch 777/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1045\n",
            "Epoch 778/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1034\n",
            "Epoch 779/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1022\n",
            "Epoch 780/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1011\n",
            "Epoch 781/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.1000\n",
            "Epoch 782/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0988\n",
            "Epoch 783/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0976\n",
            "Epoch 784/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0967\n",
            "Epoch 785/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0955\n",
            "Epoch 786/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0943\n",
            "Epoch 787/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0930\n",
            "Epoch 788/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0919\n",
            "Epoch 789/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0906\n",
            "Epoch 790/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.0895\n",
            "Epoch 791/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0884\n",
            "Epoch 792/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0872\n",
            "Epoch 793/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0863\n",
            "Epoch 794/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0852\n",
            "Epoch 795/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0842\n",
            "Epoch 796/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0830\n",
            "Epoch 797/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0820\n",
            "Epoch 798/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0810\n",
            "Epoch 799/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0799\n",
            "Epoch 800/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0790\n",
            "Epoch 801/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0780\n",
            "Epoch 802/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0769\n",
            "Epoch 803/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0759\n",
            "Epoch 804/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0747\n",
            "Epoch 805/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0735\n",
            "Epoch 806/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0723\n",
            "Epoch 807/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0712\n",
            "Epoch 808/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0701\n",
            "Epoch 809/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0691\n",
            "Epoch 810/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0680\n",
            "Epoch 811/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0669\n",
            "Epoch 812/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0658\n",
            "Epoch 813/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0648\n",
            "Epoch 814/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0638\n",
            "Epoch 815/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0630\n",
            "Epoch 816/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0620\n",
            "Epoch 817/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0610\n",
            "Epoch 818/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0602\n",
            "Epoch 819/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0592\n",
            "Epoch 820/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0582\n",
            "Epoch 821/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0571\n",
            "Epoch 822/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0563\n",
            "Epoch 823/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0554\n",
            "Epoch 824/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0544\n",
            "Epoch 825/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0535\n",
            "Epoch 826/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0526\n",
            "Epoch 827/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0516\n",
            "Epoch 828/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0508\n",
            "Epoch 829/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0498\n",
            "Epoch 830/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0488\n",
            "Epoch 831/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0479\n",
            "Epoch 832/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0469\n",
            "Epoch 833/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0462\n",
            "Epoch 834/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0450\n",
            "Epoch 835/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0441\n",
            "Epoch 836/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0433\n",
            "Epoch 837/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0422\n",
            "Epoch 838/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0412\n",
            "Epoch 839/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0402\n",
            "Epoch 840/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0391\n",
            "Epoch 841/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0382\n",
            "Epoch 842/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0372\n",
            "Epoch 843/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0363\n",
            "Epoch 844/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0355\n",
            "Epoch 845/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0346\n",
            "Epoch 846/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0337\n",
            "Epoch 847/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0330\n",
            "Epoch 848/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0320\n",
            "Epoch 849/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0311\n",
            "Epoch 850/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0303\n",
            "Epoch 851/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0294\n",
            "Epoch 852/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0285\n",
            "Epoch 853/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0276\n",
            "Epoch 854/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0268\n",
            "Epoch 855/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0258\n",
            "Epoch 856/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0250\n",
            "Epoch 857/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.0241\n",
            "Epoch 858/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0232\n",
            "Epoch 859/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0223\n",
            "Epoch 860/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0215\n",
            "Epoch 861/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0205\n",
            "Epoch 862/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0196\n",
            "Epoch 863/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.0186\n",
            "Epoch 864/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0177\n",
            "Epoch 865/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.0168\n",
            "Epoch 866/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.0159\n",
            "Epoch 867/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0150\n",
            "Epoch 868/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 2.0142\n",
            "Epoch 869/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0133\n",
            "Epoch 870/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0124\n",
            "Epoch 871/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0115\n",
            "Epoch 872/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0106\n",
            "Epoch 873/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0097\n",
            "Epoch 874/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0088\n",
            "Epoch 875/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0080\n",
            "Epoch 876/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0072\n",
            "Epoch 877/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0065\n",
            "Epoch 878/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0056\n",
            "Epoch 879/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 2.0047\n",
            "Epoch 880/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.0040\n",
            "Epoch 881/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0031\n",
            "Epoch 882/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0023\n",
            "Epoch 883/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0014\n",
            "Epoch 884/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0007\n",
            "Epoch 885/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.0000\n",
            "Epoch 886/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9991\n",
            "Epoch 887/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9984\n",
            "Epoch 888/1000\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 1.9976\n",
            "Epoch 889/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.9969\n",
            "Epoch 890/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9962\n",
            "Epoch 891/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9955\n",
            "Epoch 892/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9947\n",
            "Epoch 893/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9940\n",
            "Epoch 894/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.9934\n",
            "Epoch 895/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9928\n",
            "Epoch 896/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9920\n",
            "Epoch 897/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9913\n",
            "Epoch 898/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.9906\n",
            "Epoch 899/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.9898\n",
            "Epoch 900/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9893\n",
            "Epoch 901/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9885\n",
            "Epoch 902/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9878\n",
            "Epoch 903/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9872\n",
            "Epoch 904/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9865\n",
            "Epoch 905/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9858\n",
            "Epoch 906/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9851\n",
            "Epoch 907/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9843\n",
            "Epoch 908/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.9834\n",
            "Epoch 909/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9829\n",
            "Epoch 910/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9823\n",
            "Epoch 911/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9814\n",
            "Epoch 912/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9807\n",
            "Epoch 913/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9800\n",
            "Epoch 914/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9795\n",
            "Epoch 915/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9787\n",
            "Epoch 916/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.9781\n",
            "Epoch 917/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9775\n",
            "Epoch 918/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9768\n",
            "Epoch 919/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9760\n",
            "Epoch 920/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9753\n",
            "Epoch 921/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.9747\n",
            "Epoch 922/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9740\n",
            "Epoch 923/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9732\n",
            "Epoch 924/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9726\n",
            "Epoch 925/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9720\n",
            "Epoch 926/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9712\n",
            "Epoch 927/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9707\n",
            "Epoch 928/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9700\n",
            "Epoch 929/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9693\n",
            "Epoch 930/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9688\n",
            "Epoch 931/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9680\n",
            "Epoch 932/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9672\n",
            "Epoch 933/1000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.9664\n",
            "Epoch 934/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9659\n",
            "Epoch 935/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9650\n",
            "Epoch 936/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9643\n",
            "Epoch 937/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9637\n",
            "Epoch 938/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9631\n",
            "Epoch 939/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9623\n",
            "Epoch 940/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9616\n",
            "Epoch 941/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9609\n",
            "Epoch 942/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9603\n",
            "Epoch 943/1000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.9596\n",
            "Epoch 944/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9591\n",
            "Epoch 945/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9583\n",
            "Epoch 946/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9575\n",
            "Epoch 947/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.9569\n",
            "Epoch 948/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9562\n",
            "Epoch 949/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9557\n",
            "Epoch 950/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9550\n",
            "Epoch 951/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9544\n",
            "Epoch 952/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9537\n",
            "Epoch 953/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9531\n",
            "Epoch 954/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9522\n",
            "Epoch 955/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9514\n",
            "Epoch 956/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9507\n",
            "Epoch 957/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9498\n",
            "Epoch 958/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9490\n",
            "Epoch 959/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9484\n",
            "Epoch 960/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.9476\n",
            "Epoch 961/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9469\n",
            "Epoch 962/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9461\n",
            "Epoch 963/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9455\n",
            "Epoch 964/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9449\n",
            "Epoch 965/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.9444\n",
            "Epoch 966/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9438\n",
            "Epoch 967/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.9431\n",
            "Epoch 968/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9425\n",
            "Epoch 969/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9419\n",
            "Epoch 970/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9411\n",
            "Epoch 971/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9404\n",
            "Epoch 972/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9398\n",
            "Epoch 973/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9392\n",
            "Epoch 974/1000\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.9386\n",
            "Epoch 975/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.9379\n",
            "Epoch 976/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9374\n",
            "Epoch 977/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9367\n",
            "Epoch 978/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9363\n",
            "Epoch 979/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9356\n",
            "Epoch 980/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9349\n",
            "Epoch 981/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9342\n",
            "Epoch 982/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.9337\n",
            "Epoch 983/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9331\n",
            "Epoch 984/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9323\n",
            "Epoch 985/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9316\n",
            "Epoch 986/1000\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 1.9311\n",
            "Epoch 987/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9304\n",
            "Epoch 988/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9298\n",
            "Epoch 989/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9292\n",
            "Epoch 990/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9286\n",
            "Epoch 991/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.9281\n",
            "Epoch 992/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.9277\n",
            "Epoch 993/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9271\n",
            "Epoch 994/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9265\n",
            "Epoch 995/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9258\n",
            "Epoch 996/1000\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9252\n",
            "Epoch 997/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9246\n",
            "Epoch 998/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9239\n",
            "Epoch 999/1000\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9234\n",
            "Epoch 1000/1000\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.9228\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7e8c64a1f2b0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1hmHkZV4eR4"
      },
      "source": [
        "#defining a method to get the enbeddings which is basically the list of the weights of connections of each neuron of the word output from the last hidden layer.\n",
        "def get_embeddings(model, flag):\n",
        "    embeddings=model.layers[flag+1].get_weights()[0]\n",
        "    embeddings.reshape((len(unique_words),11))\n",
        "    return embeddings"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2xwjauD6tSD"
      },
      "source": [
        "#gettig the embeddings by calling the method\n",
        "embeddingst = get_embeddings(model, 0)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhDD3AIk6xAg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "8073856e-8b43-41cc-bfa8-e1291f1c70c9"
      },
      "source": [
        "#saving the word embeddings and visualising it as a table\n",
        "w2v_df = pd.DataFrame(embeddingst, columns = ['X1','X2','X3','X4','X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11'] )\n",
        "w2v_df['word'] = list(unique_words)\n",
        "w2v_df = w2v_df[['word', 'X1', 'X2','X3','X4','X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11']]\n",
        "w2v_df"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           word        X1        X2        X3        X4        X5        X6  \\\n",
              "0               -0.199863 -0.655473 -0.703518 -1.016073  1.439321 -0.644695   \n",
              "1        movies -0.130892  1.115118 -1.103025 -1.399521 -0.063250  0.306417   \n",
              "2        career -1.005001  0.404055 -0.980201 -0.339417  1.408288  1.162703   \n",
              "3       leaders -1.088193 -0.641086 -1.072371 -1.068406 -1.149868 -0.970825   \n",
              "4      laughter -0.634539  0.922424 -0.998790 -0.671668 -0.997517  0.442193   \n",
              "..          ...       ...       ...       ...       ...       ...       ...   \n",
              "90   professors -0.647866  0.663164 -0.462262  0.244528  0.571387  0.512443   \n",
              "91        study  0.221357  1.465070 -1.137754  0.186030 -1.104645 -0.876192   \n",
              "92     personal  0.475754 -0.750110  0.675422 -0.575966 -1.250224  0.810895   \n",
              "93  exploration  1.106535  0.058024 -0.024092  0.167983 -0.906504  0.999755   \n",
              "94        group -0.573064  0.473332  0.372358 -0.502989 -0.457612 -0.574918   \n",
              "\n",
              "          X7        X8        X9       X10       X11  \n",
              "0  -0.366031  0.148346  1.123752 -0.155499 -1.058342  \n",
              "1   0.885163 -1.407334 -0.151721  0.234154 -0.632443  \n",
              "2   0.055046  0.263228  1.121797  0.104150  0.293663  \n",
              "3  -1.123477  0.394236  0.637245  0.005265 -1.094692  \n",
              "4  -0.145300 -0.841139 -0.293299  0.819656 -0.996437  \n",
              "..       ...       ...       ...       ...       ...  \n",
              "90 -0.973065 -1.025062 -0.018254  0.226828 -0.725300  \n",
              "91  0.909095 -0.163949 -0.988707 -1.263111  0.693203  \n",
              "92  0.208186 -1.394378  0.713000 -1.195482 -0.329189  \n",
              "93  0.263698 -1.130630  1.209448 -0.288262 -1.309469  \n",
              "94 -1.200274  0.004200  0.924599  1.477448  0.250232  \n",
              "\n",
              "[95 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-905feb0e-d6e8-469f-b890-c0aab0bf2969\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>-0.199863</td>\n",
              "      <td>-0.655473</td>\n",
              "      <td>-0.703518</td>\n",
              "      <td>-1.016073</td>\n",
              "      <td>1.439321</td>\n",
              "      <td>-0.644695</td>\n",
              "      <td>-0.366031</td>\n",
              "      <td>0.148346</td>\n",
              "      <td>1.123752</td>\n",
              "      <td>-0.155499</td>\n",
              "      <td>-1.058342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>movies</td>\n",
              "      <td>-0.130892</td>\n",
              "      <td>1.115118</td>\n",
              "      <td>-1.103025</td>\n",
              "      <td>-1.399521</td>\n",
              "      <td>-0.063250</td>\n",
              "      <td>0.306417</td>\n",
              "      <td>0.885163</td>\n",
              "      <td>-1.407334</td>\n",
              "      <td>-0.151721</td>\n",
              "      <td>0.234154</td>\n",
              "      <td>-0.632443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>career</td>\n",
              "      <td>-1.005001</td>\n",
              "      <td>0.404055</td>\n",
              "      <td>-0.980201</td>\n",
              "      <td>-0.339417</td>\n",
              "      <td>1.408288</td>\n",
              "      <td>1.162703</td>\n",
              "      <td>0.055046</td>\n",
              "      <td>0.263228</td>\n",
              "      <td>1.121797</td>\n",
              "      <td>0.104150</td>\n",
              "      <td>0.293663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>leaders</td>\n",
              "      <td>-1.088193</td>\n",
              "      <td>-0.641086</td>\n",
              "      <td>-1.072371</td>\n",
              "      <td>-1.068406</td>\n",
              "      <td>-1.149868</td>\n",
              "      <td>-0.970825</td>\n",
              "      <td>-1.123477</td>\n",
              "      <td>0.394236</td>\n",
              "      <td>0.637245</td>\n",
              "      <td>0.005265</td>\n",
              "      <td>-1.094692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>laughter</td>\n",
              "      <td>-0.634539</td>\n",
              "      <td>0.922424</td>\n",
              "      <td>-0.998790</td>\n",
              "      <td>-0.671668</td>\n",
              "      <td>-0.997517</td>\n",
              "      <td>0.442193</td>\n",
              "      <td>-0.145300</td>\n",
              "      <td>-0.841139</td>\n",
              "      <td>-0.293299</td>\n",
              "      <td>0.819656</td>\n",
              "      <td>-0.996437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>professors</td>\n",
              "      <td>-0.647866</td>\n",
              "      <td>0.663164</td>\n",
              "      <td>-0.462262</td>\n",
              "      <td>0.244528</td>\n",
              "      <td>0.571387</td>\n",
              "      <td>0.512443</td>\n",
              "      <td>-0.973065</td>\n",
              "      <td>-1.025062</td>\n",
              "      <td>-0.018254</td>\n",
              "      <td>0.226828</td>\n",
              "      <td>-0.725300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>study</td>\n",
              "      <td>0.221357</td>\n",
              "      <td>1.465070</td>\n",
              "      <td>-1.137754</td>\n",
              "      <td>0.186030</td>\n",
              "      <td>-1.104645</td>\n",
              "      <td>-0.876192</td>\n",
              "      <td>0.909095</td>\n",
              "      <td>-0.163949</td>\n",
              "      <td>-0.988707</td>\n",
              "      <td>-1.263111</td>\n",
              "      <td>0.693203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>personal</td>\n",
              "      <td>0.475754</td>\n",
              "      <td>-0.750110</td>\n",
              "      <td>0.675422</td>\n",
              "      <td>-0.575966</td>\n",
              "      <td>-1.250224</td>\n",
              "      <td>0.810895</td>\n",
              "      <td>0.208186</td>\n",
              "      <td>-1.394378</td>\n",
              "      <td>0.713000</td>\n",
              "      <td>-1.195482</td>\n",
              "      <td>-0.329189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>exploration</td>\n",
              "      <td>1.106535</td>\n",
              "      <td>0.058024</td>\n",
              "      <td>-0.024092</td>\n",
              "      <td>0.167983</td>\n",
              "      <td>-0.906504</td>\n",
              "      <td>0.999755</td>\n",
              "      <td>0.263698</td>\n",
              "      <td>-1.130630</td>\n",
              "      <td>1.209448</td>\n",
              "      <td>-0.288262</td>\n",
              "      <td>-1.309469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>group</td>\n",
              "      <td>-0.573064</td>\n",
              "      <td>0.473332</td>\n",
              "      <td>0.372358</td>\n",
              "      <td>-0.502989</td>\n",
              "      <td>-0.457612</td>\n",
              "      <td>-0.574918</td>\n",
              "      <td>-1.200274</td>\n",
              "      <td>0.004200</td>\n",
              "      <td>0.924599</td>\n",
              "      <td>1.477448</td>\n",
              "      <td>0.250232</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>95 rows  12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-905feb0e-d6e8-469f-b890-c0aab0bf2969')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-905feb0e-d6e8-469f-b890-c0aab0bf2969 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-905feb0e-d6e8-469f-b890-c0aab0bf2969');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2f08043-e009-4b2b-a91c-b797967de778\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2f08043-e009-4b2b-a91c-b797967de778')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2f08043-e009-4b2b-a91c-b797967de778 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDqQvouB6zPQ"
      },
      "source": [
        "#saving the word embeddings a dictionary of arrays where key is the word and the value is the wordvector in the form of an array\n",
        "wordembeddings={}\n",
        "for i in w2v_df['word']:\n",
        "  vec=[]\n",
        "  j=0\n",
        "  vec.append(w2v_df['X1'][j])\n",
        "  vec.append(w2v_df['X2'][j])\n",
        "  vec.append(w2v_df['X3'][j])\n",
        "  vec.append(w2v_df['X4'][j])\n",
        "  vec.append(w2v_df['X5'][j])\n",
        "  vec.append(w2v_df['X6'][j])\n",
        "  vec.append(w2v_df['X7'][j])\n",
        "  vec.append(w2v_df['X8'][j])\n",
        "  vec.append(w2v_df['X9'][j])\n",
        "  vec.append(w2v_df['X10'][j])\n",
        "  vec.append(w2v_df['X11'][j])\n",
        "  j+=1\n",
        "  wordembeddings[i]= np.asarray(vec)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfEVm39q63Dw"
      },
      "source": [
        "#finding the sentence vectors by adding the word vectors of the words in the sentence after cleaning them and dividing by the number of words in that sentence\n",
        "sentence_vect=[]\n",
        "for i in cleaned:\n",
        "  if len(i)!=0:\n",
        "    v = sum([wordembeddings.get(w, np.zeros((11,))) for w in i.split()])/(len(i.split())+0.000001)\n",
        "  else:\n",
        "    v=np.zeros((11,))\n",
        "  sentence_vect.append(v)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2IXgru4669I"
      },
      "source": [
        "#defining the similarity matrix\n",
        "sim_mat=np.zeros([len(cleaned),len(cleaned)])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpiGiA6f6-KI"
      },
      "source": [
        "\n",
        "#defing a method for finding out cosine similarity\n",
        "def cossim(g,h):\n",
        "  l=len(g)\n",
        "  x,y,z=0,0,0\n",
        "  for i in range(0,l):\n",
        "    x=x+g[i]*h[i]\n",
        "    y=y+g[i]**2\n",
        "    z=z+h[i]**2\n",
        "  x=x/(y*z)\n",
        "  return x"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6ocGT-m7Big"
      },
      "source": [
        "#filling up the similarity matrix by finding out the similarity between sentences using cossim method\n",
        "for i in range(0, len(cleaned)):\n",
        "  for j in range(0, len(cleaned)):\n",
        "    if i!=j:\n",
        "      g=sentence_vect[i]\n",
        "      h=sentence_vect[j]\n",
        "      sim_mat[i][j]=cossim(g,h)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P2GJQEa7D3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a90cfd9-e801-49d8-80ac-9eacaea6e963"
      },
      "source": [
        "#similarity matrix\n",
        "sim_mat"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.14189873, 0.14189873, 0.14189873, 0.14189875,\n",
              "        0.14189873, 0.14189873, 0.14189873, 0.14189873, 0.14189874],\n",
              "       [0.14189873, 0.        , 0.14189872, 0.14189873, 0.14189875,\n",
              "        0.14189873, 0.14189873, 0.14189872, 0.14189873, 0.14189873],\n",
              "       [0.14189873, 0.14189872, 0.        , 0.14189872, 0.14189874,\n",
              "        0.14189873, 0.14189872, 0.14189872, 0.14189873, 0.14189873],\n",
              "       [0.14189873, 0.14189873, 0.14189872, 0.        , 0.14189875,\n",
              "        0.14189873, 0.14189873, 0.14189872, 0.14189873, 0.14189873],\n",
              "       [0.14189875, 0.14189875, 0.14189874, 0.14189875, 0.        ,\n",
              "        0.14189875, 0.14189875, 0.14189874, 0.14189875, 0.14189875],\n",
              "       [0.14189873, 0.14189873, 0.14189873, 0.14189873, 0.14189875,\n",
              "        0.        , 0.14189873, 0.14189873, 0.14189873, 0.14189873],\n",
              "       [0.14189873, 0.14189873, 0.14189872, 0.14189873, 0.14189875,\n",
              "        0.14189873, 0.        , 0.14189872, 0.14189873, 0.14189873],\n",
              "       [0.14189873, 0.14189872, 0.14189872, 0.14189872, 0.14189874,\n",
              "        0.14189873, 0.14189872, 0.        , 0.14189873, 0.14189873],\n",
              "       [0.14189873, 0.14189873, 0.14189873, 0.14189873, 0.14189875,\n",
              "        0.14189873, 0.14189873, 0.14189873, 0.        , 0.14189873],\n",
              "       [0.14189874, 0.14189873, 0.14189873, 0.14189873, 0.14189875,\n",
              "        0.14189873, 0.14189873, 0.14189873, 0.14189873, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfI8IvHF7HhA"
      },
      "source": [
        "#finding the edge values ,that is by how much each sentence is similar to other sentences\n",
        "edge=[]\n",
        "for i in range(0,len(cleaned)):\n",
        "  for j in range(i+1,len(cleaned)):\n",
        "    dict={}\n",
        "    dict['weight']=sim_mat[i][j]\n",
        "    edge=edge+[(i,j,dict)]\n",
        "edge=(edge)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsJWf9Yk7KrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b06b4f-fa5d-4cb3-bf22-6c04be9d07ca"
      },
      "source": [
        "edge"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1, {'weight': 0.14189873334205996}),\n",
              " (0, 2, {'weight': 0.14189872747544116}),\n",
              " (0, 3, {'weight': 0.14189873334205996}),\n",
              " (0, 4, {'weight': 0.1418987499034069}),\n",
              " (0, 5, {'weight': 0.14189873446225135}),\n",
              " (0, 6, {'weight': 0.14189873034766323}),\n",
              " (0, 7, {'weight': 0.14189872747544116}),\n",
              " (0, 8, {'weight': 0.14189873475757137}),\n",
              " (0, 9, {'weight': 0.14189873657126173}),\n",
              " (1, 2, {'weight': 0.141898723683667}),\n",
              " (1, 3, {'weight': 0.14189872895020858}),\n",
              " (1, 4, {'weight': 0.14189874607412786}),\n",
              " (1, 5, {'weight': 0.14189873123304947}),\n",
              " (1, 6, {'weight': 0.1418987259558119}),\n",
              " (1, 7, {'weight': 0.141898723683667}),\n",
              " (1, 8, {'weight': 0.14189873032821507}),\n",
              " (1, 9, {'weight': 0.14189873334205996}),\n",
              " (2, 3, {'weight': 0.141898723683667}),\n",
              " (2, 4, {'weight': 0.14189874290785734}),\n",
              " (2, 5, {'weight': 0.14189872536643053}),\n",
              " (2, 6, {'weight': 0.14189872068927029}),\n",
              " (2, 7, {'weight': 0.14189871781704805}),\n",
              " (2, 8, {'weight': 0.14189872506167317}),\n",
              " (2, 9, {'weight': 0.14189872747544116}),\n",
              " (3, 4, {'weight': 0.14189874607412786}),\n",
              " (3, 5, {'weight': 0.14189873123304947}),\n",
              " (3, 6, {'weight': 0.1418987259558119}),\n",
              " (3, 7, {'weight': 0.141898723683667}),\n",
              " (3, 8, {'weight': 0.14189873032821507}),\n",
              " (3, 9, {'weight': 0.14189873334205996}),\n",
              " (4, 5, {'weight': 0.14189874779439685}),\n",
              " (4, 6, {'weight': 0.14189874548004053}),\n",
              " (4, 7, {'weight': 0.14189874290785734}),\n",
              " (4, 8, {'weight': 0.1418987477896786}),\n",
              " (4, 9, {'weight': 0.1418987499034069}),\n",
              " (5, 6, {'weight': 0.14189872823865274}),\n",
              " (5, 7, {'weight': 0.14189872536643053}),\n",
              " (5, 8, {'weight': 0.14189873264856073}),\n",
              " (5, 9, {'weight': 0.14189873446225135}),\n",
              " (6, 7, {'weight': 0.14189872068927029}),\n",
              " (6, 8, {'weight': 0.14189872733381828}),\n",
              " (6, 9, {'weight': 0.14189873034766323}),\n",
              " (7, 8, {'weight': 0.14189872506167317}),\n",
              " (7, 9, {'weight': 0.14189872747544116}),\n",
              " (8, 9, {'weight': 0.14189873475757137})]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOo7xAKb7NKg"
      },
      "source": [
        "\n",
        "#finding the score of each sentence and storing it in a dictionary. the score is the mean of the edge values for each sentence with every other sentence.\n",
        "scores1={}\n",
        "k=0\n",
        "while(k<len(cor)):\n",
        "  sum=0\n",
        "  for i in edge:\n",
        "    if i[0] == k:\n",
        "      sum+=i[2]['weight']\n",
        "    elif i[1] == k:\n",
        "      sum+=i[2]['weight']\n",
        "  sum=sum/len(cor)\n",
        "  scores1[k]=sum\n",
        "  k+=1\n",
        ""
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI3EUGWK7ZpQ"
      },
      "source": [
        "#reverse sorting ranked_sentences to get the sentences with higher scores\n",
        "ranked_sentences = sorted(((scores1[i],s) for i,s in enumerate(cor)), reverse=True)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8skD5GV7fCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44189562-4e97-4712-d59f-a2b7a88407da"
      },
      "source": [
        "#sorting the sentences in the reverse manner for getting sentences with high scores and printing them.\n",
        "for i in range(5):\n",
        "  print(ranked_sentences[i][1])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yet, student life is not just about academics.\n",
            "Student life is a dynamic and transformative period filled with a multitude of experiences and challenges.\n",
            "It's a time of both challenges and triumphs, a period that shapes future leaders, thinkers, and innovators.\n",
            "It's a vibrant tapestry of social interactions, extracurricular activities, and newfound friendships.\n",
            "The pursuit of knowledge is intertwined with the pursuit of self-expression, and students often discover their true interests, values, and career aspirations during this transformative phase.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw1uEbvM7uN5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}